{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfq5xMsASec4QShv2N8s/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csabiu/KAML-2025/blob/main/KAML_catalogues_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install library for accessing numerous astronomical datasets"
      ],
      "metadata": {
        "id": "BuSCQvsMapSp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k61yaoknLsXw"
      },
      "outputs": [],
      "source": [
        "!pip install astroquery"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from astroquery.sdss import SDSS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ARuY60QvLu6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# an SQL query for SDSS data\n",
        "query = \"\"\"\n",
        "SELECT TOP 10000\n",
        "       p.ra, p.dec,\n",
        "       p.u, p.g, p.r, p.i, p.z,\n",
        "       s.z as redshift,\n",
        "       s.class as specClass\n",
        "FROM SpecObjAll s\n",
        "JOIN PhotoObjAll p ON s.bestObjID = p.objid\n",
        "WHERE s.class in ('STAR', 'GALAXY', 'QSO')\n",
        "  AND p.clean = 1\n",
        "  AND p.u between 0 AND 30  -- Exclude obviously invalid magnitudes\n",
        "  AND p.g between 0 AND 30\n",
        "  AND p.r between 0 AND 30\n",
        "  AND p.i between 0 AND 30\n",
        "  AND p.z between 0 AND 30\n",
        "ORDER BY NEWID()  -- Randomize the sample\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "W86Rlf0OL1WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = SDSS.query_sql(query) # sometimes this produces an error message - try re-running it OR skip to the next cells"
      ],
      "metadata": {
        "id": "kAc_3Wu3L7hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sdss = res.to_pandas()\n",
        "df_sdss.head()"
      ],
      "metadata": {
        "id": "9SUwSIIQL-CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If there are errors accessing the SDSS data then uncomment the following lines...."
      ],
      "metadata": {
        "id": "sOaMnZITdDgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_sdss = pd.read_csv(\"https://archive.kasi.re.kr/bigdata/temp/KAML_catalogues.csv\", header=0)\n",
        "#df_sdss.head()"
      ],
      "metadata": {
        "id": "H6qZ_cjhcKgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histogram of the 5 SDSS magnitudes\n",
        "df_sdss[[\"u\", \"g\", \"r\", \"i\", \"z\"]].hist(bins=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ozWXRD9-4FIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of classes\n",
        "df_sdss[\"specClass\"].value_counts().plot(kind=\"pie\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "49agSJhffHcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets make 4 additional pieces of information: color\n",
        "df_sdss['u_g'] = df_sdss['u'] - df_sdss['g'] # u-g\n",
        "df_sdss['g_r'] = df_sdss['g'] - df_sdss['r'] # g-r\n",
        "df_sdss['r_i'] = df_sdss['r'] - df_sdss['i'] # r-i\n",
        "df_sdss['i_z'] = df_sdss['i'] - df_sdss['z'] # i-z\n",
        "\n",
        "# View the new color-index columns\n",
        "df_sdss[['u_g', 'g_r', 'r_i', 'i_z']].head()"
      ],
      "metadata": {
        "id": "LMX6Y-nyNXzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a color-magnitude diagram\n",
        "class_colors = {\n",
        "    'STAR': 'blue',\n",
        "    'GALAXY': 'red',\n",
        "    'QSO': 'green'\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "for cls, color in class_colors.items():\n",
        "    subset = df_sdss[df_sdss['specClass'] == cls]\n",
        "    plt.scatter(subset['g_r'], subset['g'], c=color, label=cls, alpha=0.2, s=1.5)\n",
        "\n",
        "plt.gca().invert_yaxis()\n",
        "plt.xlabel('g - r (Color Index)')\n",
        "plt.ylabel('g (Magnitude)')\n",
        "plt.title('Color-Magnitude Diagram by Class')\n",
        "plt.xlim([-1,6])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B44p1aWh4lnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above color-magnitude diagram is not enough to clearly seperate the 3 types of object. So lets try and do some machine learning on this data to help us predict the correct classification"
      ],
      "metadata": {
        "id": "ViBjn-Ojd0Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = [\"u\", \"g\", \"r\", \"i\", \"z\", \"u_g\", \"g_r\", \"r_i\", \"i_z\"]  # magnitudes and colors\n",
        "labels = \"specClass\"\n",
        "\n",
        "X = df_sdss[features].values\n",
        "y = df_sdss[labels].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,   # use 20% of the data for testing\n",
        "                                                    random_state=42,)\n",
        "                                                    #stratify=y)\n",
        "\n",
        "print(\"Training inputs: \",X_train.shape)\n",
        "print(\"Training outputs: \",y_train.shape)\n",
        "print(\"Testing inputs: \",X_test.shape)\n",
        "print(\"Testing outputs: \",y_test.shape)"
      ],
      "metadata": {
        "id": "lsFnU7qIOpch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task: Classification**\n",
        "\n",
        "We want to train a machine to classify the phoometric sources as either Star, Galaxy or QSO\n",
        "\n",
        "**Decision Tree**\n",
        "\n",
        "A decision tree is a simple binary classification that aims to maximise the entropy between the seperated objects after each 'decision'\n",
        "\n",
        "Decisions are binary and hierachical, they can be many levels deep."
      ],
      "metadata": {
        "id": "LNIl3MPiVCL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=2,random_state=42,)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)"
      ],
      "metadata": {
        "id": "ZbyuSYrjPWrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.externals.six import StringIO\n",
        "from IPython.display import Image\n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "\n",
        "#dot_data=export_graphviz(dt)\n",
        "dot_data = export_graphviz(\n",
        "    dt,\n",
        "    out_file=None,\n",
        "    feature_names=features,\n",
        "    class_names=[\"STAR\", \"GALAXY\", \"QSO\"],\n",
        "    filled=True,\n",
        "    rounded=True)\n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "\n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "byILFWmdPgiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "skZVpEIkPdny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are brief definitions of **precision**, **recall**, and **F1**. They provide simple metrics with which to assess the performance of classification methods. We can use these to test hyper-parameters of an alogorithm or compare alogorithms with each other.\n",
        "\n",
        "---\n",
        "\n",
        "## Precision\n",
        "**Precision** is the fraction of predicted positives (i.e., the objects your model labeled as positive) that are actually positive:\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "- **TP** = True Positives: Items correctly labeled as positive.  \n",
        "- **FP** = False Positives: Items incorrectly labeled as positive.\n",
        "\n",
        "---\n",
        "\n",
        "## Recall\n",
        "**Recall** (or sensitivity) is the fraction of actual positives that are correctly identified:\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "- **TP** = True Positives.  \n",
        "- **FN** = False Negatives: Items that were positive but incorrectly labeled as negative.\n",
        "\n",
        "---\n",
        "\n",
        "## F1 Score\n",
        "The **F1 score** is the harmonic mean of precision and recall:\n",
        "\n",
        "$$\n",
        "F1 = 2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}\n",
        "$$\n",
        "\n",
        "F1 ranges between 0 and 1, with 1 indicating perfect precision and recall."
      ],
      "metadata": {
        "id": "jeja18KDN5Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is how you can compute the above metrics...\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "print('precision:',precision)\n",
        "recall    = recall_score(y_test, y_pred, average='macro')\n",
        "print('recall:',recall)\n",
        "f1    = f1_score(y_test, y_pred, average='macro')\n",
        "print('f1:',f1)"
      ],
      "metadata": {
        "id": "LuGX8oeehdvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1:\n",
        "* Create a plot of the **precision** as a function of **max depth** of the decision tree. try depths values from 1-20. show precision for test and train samples\n",
        "* Do the same for **recall**"
      ],
      "metadata": {
        "id": "dFLKXU5eidim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "... blank ...\n",
        "\n"
      ],
      "metadata": {
        "id": "t_ahjFWDN9At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Random Forest is a machine learning algorithm that belongs to the family of ensemble methods.  It operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees.  Essentially, it leverages the \"wisdom of the crowd\" – many relatively weak learners (decision trees) combine to form a powerful predictor.\n",
        "\n",
        "Here's a breakdown of key aspects:\n",
        "\n",
        "**1. Decision Trees:**  The foundation of a Random Forest is the decision tree.  Each tree is built on a random subset of the training data (bootstrap aggregating or bagging).  This means that each tree doesn't see the entire dataset, introducing diversity.  Furthermore, at each node of a tree, a random subset of features is considered for the split. This further decorrelates the trees, as they will be based on different features and different subsets of the training data.\n",
        "\n",
        "**2. Bagging (Bootstrap Aggregating):**  This technique involves creating multiple subsets of the original training data by randomly sampling with replacement.  This means some data points might appear multiple times in a subset, while others might be left out entirely.  Each subset is used to train a different decision tree.  This randomness helps to reduce the variance of the model.\n",
        "\n",
        "**3. Random Subspace (Feature Randomness):** At each node of each decision tree, the algorithm considers only a random subset of the features when deciding on the best split.  This prevents individual trees from becoming overly dependent on a single feature, increasing the diversity of the forest.\n",
        "\n",
        "**4. Prediction:** To make a prediction for a new data point, the Random Forest feeds the data point through each decision tree in the forest. Each tree produces a prediction, and the final prediction is an aggregate of the individual tree predictions.  For classification, this is typically the most frequent class (mode); for regression, it's the average of the predictions.\n",
        "\n",
        "\n",
        "**Advantages of Random Forests:**\n",
        "\n",
        "* **High accuracy:** Random Forests often achieve high accuracy compared to single decision trees due to the combination of multiple trees and the reduced overfitting.\n",
        "* **Robustness to outliers:** The use of multiple trees and bootstrapping makes the model less sensitive to outliers in the data.\n",
        "* **Handles high dimensionality well:** Feature randomness helps the model handle a large number of features efficiently.\n",
        "* **Can handle missing values:** Random Forests can be adapted to deal with missing data without requiring imputation.\n",
        "* **Provides feature importance:**  The algorithm can estimate the relative importance of each feature in the prediction, allowing for feature selection and better understanding of the model.\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "* **Computational cost:** Training many decision trees can be computationally expensive, especially with large datasets.\n",
        "* **Black box nature:** While feature importance is available, it can be difficult to interpret the complete decision-making process of a Random Forest.\n",
        "\n",
        "\n",
        "In the provided code example, a Random Forest isn't directly used. However, the analysis explores decision trees and their performance, illustrating some of the fundamental concepts that apply to Random Forests as well, particularly regarding feature selection, model evaluation (precision, recall, F1-score), and the impact of model parameters (max depth).  You can easily replace the `DecisionTreeClassifier` with `RandomForestClassifier` to apply these same evaluation methods to a Random Forest.\n",
        "\n"
      ],
      "metadata": {
        "id": "vQFaKKjO701d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a range of tree counts to test\n",
        "n_estimators_range = range(1, 15, 1)\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "precisions_train = []\n",
        "recalls_train = []\n",
        "f1_scores_train = []\n",
        "\n",
        "# Use 'binary' or 'macro' depending on your task\n",
        "average_type = 'macro'  # or 'weighted' or 'binary'\n",
        "\n",
        "for n in n_estimators_range:\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=n,\n",
        "        max_depth=8,\n",
        "        random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    y_pred_train = clf.predict(X_train)\n",
        "\n",
        "    precisions.append(precision_score(y_test, y_pred, average=average_type))\n",
        "    recalls.append(recall_score(y_test, y_pred, average=average_type))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average=average_type))\n",
        "\n",
        "    precisions_train.append(precision_score(y_train, y_pred_train, average=average_type))\n",
        "    recalls_train.append(recall_score(y_train, y_pred_train, average=average_type))\n",
        "    f1_scores_train.append(f1_score(y_train, y_pred_train, average=average_type))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(n_estimators_range, precisions, label='Precision',color='b')\n",
        "plt.plot(n_estimators_range, recalls, label='Recall',color='r')\n",
        "plt.plot(n_estimators_range, f1_scores, label='F1 Score',color='g')\n",
        "\n",
        "plt.plot(n_estimators_range, precisions_train,ls='--',color='b')\n",
        "plt.plot(n_estimators_range, recalls_train,ls='--',color='r')\n",
        "plt.plot(n_estimators_range, f1_scores_train,ls='--',color='g')\n",
        "\n",
        "plt.xlabel('Number of Trees (n_estimators)')\n",
        "plt.ylabel('Score')\n",
        "plt.title(f'Random Forest Performance vs. Number of Trees ({average_type} average)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vMKrUDNS8J-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A neural network is made up of layers:\n",
        "\n",
        "**Input Layer**\n",
        "\n",
        "Each node represents a feature of your data (e.g., color indices like g−rg−r, r−ir−i, etc.).\n",
        "\n",
        "**Hidden Layers**\n",
        "\n",
        "One or more layers that process and transform the input. Each neuron in a hidden layer performs:\n",
        "\n",
        "$$z=w_1x_1+w_2x_2+...+w_nx_n+b$$\n",
        "\n",
        "followed by a nonlinear activation function like **sigmoid** or **tanh** etc etc\n",
        "\n",
        "**Output Layer**\n",
        "\n",
        "Produces the final prediction. For example, a softmax output layer can give probabilities for classes like STAR, GALAXY, or QSO.\n",
        "\n",
        "The softmax function is used in the output layer of a neural network for multi-class classification. It converts a vector of raw scores (called logits) into probabilities that sum to 1 — making it easy to interpret the output as the model's confidence in each class.\n",
        "\n",
        "If you have output scores $$z_1​,z_2​,...,z_K$$​ for K classes, the softmax function turns them into probabilities $$p_1,p_2,...,p_K$$​ like this:\n",
        "$$\\text{softmax}(z_i)=\\frac{e^{z_i}}{\\sum_i^K e^{z_j}}$$\n"
      ],
      "metadata": {
        "id": "Am9GmUb7-Ze6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: A simple neural network for star, galaxy, QSO classification\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_categorical = keras.utils.to_categorical(y_encoded, num_classes=3)  # 3 classes\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='sigmoid', input_shape=(X.shape[1],)),  # Input layer\n",
        "    keras.layers.Dense(64, activation='sigmoid'),  # Hidden layer\n",
        "    keras.layers.Dense(3, activation='softmax')  # Output layer (3 classes)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9p81_bqR7q_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data: train 80% - test 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "2O57uMhSS0sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training history\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_test_decoded = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "# Convert predictions back to original labels\n",
        "y_pred_labels = le.inverse_transform(y_pred)\n",
        "y_test_labels = le.inverse_transform(y_test_decoded)\n",
        "\n",
        "\n",
        "print(classification_report(y_test_labels,y_pred_labels))"
      ],
      "metadata": {
        "id": "ivuWlbc8S4bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2:\n",
        "\n",
        "\n",
        "\n",
        "*   Try different choices of number of layers and neurons per layer\n",
        "*   What is the best **precision** and **recall** values you can obtain?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UrMHalnl2FER"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFKacVKm1ojG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}