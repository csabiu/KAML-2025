{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csabiu/KAML-2025/blob/main/KAML_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG_dgosvNAVY"
      },
      "source": [
        "# Import the necessary packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EISEU0Zp74tP"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flhXCY54TZt-"
      },
      "source": [
        "#Download data sample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/csabiu/ML_tutorial/raw/refs/heads/master/class.tar.gz.parta{a,b,c,d,e,f,g,h,i} > tmp\n",
        "!cat class.tar.gz.parta* > class.tar.gz\n",
        "!gunzip class.tar.gz\n",
        "!tar -xvf class.tar > tmp\n",
        "!rm class.tar*\n",
        "!rm tmp\n",
        "!ls"
      ],
      "metadata": {
        "id": "AtV38KlzdpOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aletrnative\n",
        "#!wget https://archive.kasi.re.kr/bigdata/temp/class.tar.gz\n",
        "#!tar zxf class.tar.gz\n",
        "#!rm class.tar.gz\n",
        "#!ls"
      ],
      "metadata": {
        "id": "F13m5mB3jihl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rDlAX4DYVIb"
      },
      "source": [
        "## Lets look at an image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfJ_dVUq7_VL"
      },
      "source": [
        "jpgfile = Image. open(\"class/100134.jpg\")\n",
        "plt.imshow(jpgfile)\n",
        "print(np.shape(jpgfile))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDBKAMY6mWVa"
      },
      "source": [
        "# Lets crop it and de-center"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT5KsvVuCfwg"
      },
      "source": [
        "# Define the random ranslation shift\n",
        "x_shift = np.random.randint(-20,20)\n",
        "y_shift = np.random.randint(-20,20)\n",
        "\n",
        "# Perform the translation shift using image.transform()\n",
        "translated_image = jpgfile.transform(jpgfile.size, Image.AFFINE, (1, 0, x_shift, 0, 1, y_shift))\n",
        "cropped_image = translated_image.crop((112,112,312,312))\n",
        "\n",
        "# Display the translated image\n",
        "plt.figure()\n",
        "plt.imshow(cropped_image)\n",
        "plt.title('Translated Image')\n",
        "plt.show()\n",
        "\n",
        "# Print shape of translated image\n",
        "print(np.shape(translated_image))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpk7x_HPmfJB"
      },
      "source": [
        "# And lower the resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgTBf8OACg6e"
      },
      "source": [
        "target_size = 32\n",
        "lowres_image = cropped_image.resize((target_size,target_size),Image.Resampling.LANCZOS)\n",
        "plt.imshow(lowres_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU08p38fDENp"
      },
      "source": [
        "# Split into RGB colors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt6vCgSgCrQx"
      },
      "source": [
        "r,g,b=lowres_image.split()\n",
        "plt.imshow(r)\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvA3-1_IDRGY"
      },
      "source": [
        "# Normalise the pixel values to (0,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0tNQQC5Dd0o"
      },
      "source": [
        "im=np.zeros((target_size,target_size))\n",
        "im[:,:]=r\n",
        "im=im/255.\n",
        "plt.imshow(im)\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bywkS7ztkG6Y"
      },
      "source": [
        "# Load the labels (truth) data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tz5S6kum7dF"
      },
      "source": [
        "(Image ID, galaxy type) - 0=smooth, 1=featured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-WsMsNtkSc0"
      },
      "source": [
        "data=np.loadtxt(\"class/truth.txt\",dtype='i')\n",
        "print(np.shape(data))\n",
        "labels=data[:,1]\n",
        "\n",
        "print(data[:10,:]) # print first 10 entries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqfh_2jSiJZ_"
      },
      "source": [
        "# Lets transform all the images and save into an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqB7qRK2If7r"
      },
      "source": [
        "images=[]\n",
        "\n",
        "for i in (data[:,0]):\n",
        "  x_shift = np.random.randint(-20,20)\n",
        "  y_shift = np.random.randint(-20,20)\n",
        "  filename=str(int(i))+\".jpg\"\n",
        "  jpgfile = Image. open(\"./class/\"+filename)\n",
        "  translated_image = jpgfile.transform(jpgfile.size, Image.AFFINE, (1, 0, x_shift, 0, 1, y_shift))\n",
        "  cropped_image = translated_image.crop((112,112,312,312))\n",
        "  lowres_image = cropped_image.resize((target_size,target_size),Image.Resampling.LANCZOS)\n",
        "  images.append(np.array(lowres_image))\n",
        "\n",
        "images=np.asarray(images)\n",
        "images=images/255.\n",
        "\n",
        "# remove color - make each chanel the same by averaging\n",
        "images[:,:,:,0]=np.mean(images,axis=3)\n",
        "images[:,:,:,1]=images[:,:,:,0]\n",
        "images[:,:,:,2]=images[:,:,:,0]\n",
        "print(np.shape(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zithpd4doa6E"
      },
      "source": [
        "# Split images and labels into training and test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_label, test_label = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
        "\n",
        "print(np.shape(train_data))\n",
        "print(np.shape(train_label))\n",
        "print(np.shape(test_data))\n",
        "print(np.shape(test_label))"
      ],
      "metadata": {
        "id": "pvy86BzxJv-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C2OtmvCSIzL"
      },
      "source": [
        "class_names = ['Smooth', 'Features']\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_data[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[int(train_label[i])])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omY4d8QsLqvw"
      },
      "source": [
        "# Define a simple neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDV4GoCNLuC0"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(target_size, target_size, 3)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# early stopping callback\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True, min_delta=0.0001)\n",
        "\n",
        "# reduce lr on plateau callback\n",
        "rlr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_delta=0.0001)"
      ],
      "metadata": {
        "id": "5uyFVEVdi3Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysjpGl0rL8Pq"
      },
      "source": [
        "hist = model.fit(train_data, train_label, epochs=100, validation_split=0.2, callbacks=[es, rlr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFa8zm3bMfJE"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_data, test_label)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lrb6f-WfyR5"
      },
      "source": [
        "Set up some of plotting functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training loss and accuracy history\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "AmyfnW0aM7EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTF80GvYTgX7"
      },
      "source": [
        "# plotting functions\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[int(true_label)]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([0,1])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(2), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvb2IYPrgenO"
      },
      "source": [
        "# Make predictions on test data from the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRjm5bbRgjib"
      },
      "source": [
        "predictions = (model.predict(test_data[:,:,:]))\n",
        "\n",
        "print(\"First 10 galaxies\")\n",
        "print(\"Predicted:\",np.argmax(predictions[1:11],axis=1))\n",
        "print(\"Truth:    \",np.int_(test_label[1:11]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLvcJC0fhsVl"
      },
      "source": [
        "# Lets visialise these classifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt1DDbunTiLW"
      },
      "source": [
        "i = 4\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, np.int_(test_label), test_data)\n",
        "f=plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  np.int_(test_label))\n",
        "f.axes.set_xticklabels([\"smooth\",\"features\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8jFdlIEfobw"
      },
      "source": [
        " Plot the first X test images, their predicted label, and the true label\n",
        " Color correct predictions in blue, incorrect predictions in red"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxgmHQyufSEW"
      },
      "source": [
        "num_rows = 5\n",
        "num_cols = 4\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, np.int_(test_label), test_data)\n",
        "  f=plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  f.axes.set_xticklabels([\"smooth\",\"features\"])\n",
        "  plot_value_array(i, predictions, np.int_(test_label))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQHgqPjVKUnS"
      },
      "source": [
        "# Define a new convolutional neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnNJKkhuRoeW"
      },
      "source": [
        "def create_cnn_model():\n",
        "  keras.backend.clear_session()\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Input(shape=(target_size, target_size,3)))\n",
        "  model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dropout(0.25))\n",
        "  model.add(keras.layers.Dense(64, activation='relu'))\n",
        "  model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FjkMvGOKe1_"
      },
      "source": [
        "# Train the model on the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5938YM77pKdc"
      },
      "source": [
        "hist = model.fit(train_data, train_label, epochs=100, validation_split=0.2, callbacks=[es, rlr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fgg-xJ03_SA"
      },
      "source": [
        "# Now make prediction and visualise\n",
        "# Compare to previous plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history again\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n"
      ],
      "metadata": {
        "id": "fjBS_Y9zP5aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jgRTlDK4EbC"
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 4\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, np.int_(test_label), test_data)\n",
        "  f=plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  f.axes.set_xticklabels([\"smooth\",\"features\"])\n",
        "  plot_value_array(i, predictions, np.int_(test_label))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute evaluation metrics: precision and recall\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "print(\"Precision:\",precision_score(np.int_(test_label),np.argmax(predictions,axis=1)))\n",
        "print(\"Recall:\",recall_score(np.int_(test_label),np.argmax(predictions,axis=1)))\n"
      ],
      "metadata": {
        "id": "UmxZTnyBnkXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1:\n",
        "*   Create you own CNN with different number of layers.\n",
        "*   Can you improve the precision and recall values?\n"
      ],
      "metadata": {
        "id": "WVIW5J0cn3R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...blank..."
      ],
      "metadata": {
        "id": "xb5_c3thkPfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej4rGbVp362K"
      },
      "source": [
        "# Now add some data augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzNG7nVDzcgQ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import from tensorflow.keras.preprocessing.image\n",
        "\n",
        "# add data augmentation using a generator\n",
        "datagen = ImageDataGenerator(width_shift_range=.1,\n",
        "                             height_shift_range=.1,\n",
        "                             horizontal_flip=True,\n",
        "                             vertical_flip=True,\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "datagen.fit(train_data[:-100])\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# visualise\n",
        "\n",
        "idx = 0\n",
        "original = train_data[idx]            # shape (H, W, C), dtype float32 or uint8\n",
        "\n",
        "iterator = datagen.flow(\n",
        "    original[np.newaxis, ...],        # add batch dimension\n",
        "    batch_size=1,\n",
        "    shuffle=False)\n",
        "augmented = next(iterator)[0]         # take the first (and only) image\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "axes[0].imshow((original))\n",
        "axes[0].set_title(\"Original\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow((augmented))\n",
        "axes[1].set_title(\"Augmented\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create fresh model\n",
        "model = create_cnn_model()\n",
        "\n",
        "# fit model with data augmentation!\n",
        "hist = model.fit(datagen.flow(train_data[:-100], train_label[:-100],\n",
        "                    batch_size=64),\n",
        "                    epochs=100,\n",
        "                    validation_data=(test_data[-100:], test_label[-100:]),\n",
        "                    callbacks=[es, rlr]\n",
        "                    )"
      ],
      "metadata": {
        "id": "1FZT51o6rP3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg-v3v-PKjDg"
      },
      "source": [
        "# Test the trained model on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68XyIpD7pNId"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_data, test_label)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history again\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "YgqW29fKlIuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjsAWOklDUE3"
      },
      "source": [
        "# Now make prediction and visualise\n",
        "# Compare to previous plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhiK5vQQBueS"
      },
      "source": [
        "predictions = (model.predict(test_data))\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 4\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, np.int_(test_label), test_data)\n",
        "  f=plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  f.axes.set_xticklabels([\"smooth\",\"features\"])\n",
        "  plot_value_array(i, predictions, np.int_(test_label))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# precision and recall\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"Precision:\",precision_score(np.int_(test_label),np.argmax(predictions,axis=1)))\n",
        "print(\"Recall:\",recall_score(np.int_(test_label),np.argmax(predictions,axis=1)))"
      ],
      "metadata": {
        "id": "4CWHpzIqtoGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "sr6Bx_Scoltc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajzAci0GC5_O"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load a pretrained network\n",
        "# Load the VGG16 model without the top classification layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(target_size, target_size, 3)))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new classification layer\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x) # 2 classes: smooth, featured\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "hist = model.fit(datagen.flow(train_data[:-100], train_label[:-100],\n",
        "                    batch_size=64),\n",
        "                    epochs=20,\n",
        "                    validation_data=(test_data[-100:], test_label[-100:]),\n",
        "                    )"
      ],
      "metadata": {
        "id": "h4NDgwwnUh4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning"
      ],
      "metadata": {
        "id": "FdG1zaybpMDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.layers"
      ],
      "metadata": {
        "id": "K6000Erh-R5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the top layers of the base model\n",
        "for layer in base_model.layers[-10:]: # unfreeze last 5 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), # Lower learning rate\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "X5HBPuRdUtvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "hist2 = model.fit(datagen.flow(train_data[:-100], train_label[:-100],\n",
        "                    batch_size=64),\n",
        "                    epochs=20,\n",
        "                    validation_data=(test_data[-100:], test_label[-100:]),\n",
        "                  )"
      ],
      "metadata": {
        "id": "9SeB6L1MVUBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'],'r-')\n",
        "plt.plot(hist.history['val_accuracy'],'b-')\n",
        "plt.plot(np.arange(19,39),hist2.history['accuracy'],'r-')\n",
        "plt.plot(np.arange(19,39),hist2.history['val_accuracy'],'b-')\n",
        "\n",
        "plt.axvline(x=19,color='k',linestyle='--')\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "8qgwRk2GVY3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (model.predict(test_data))\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 4\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, np.int_(test_label), test_data)\n",
        "  f=plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  f.axes.set_xticklabels([\"smooth\",\"features\"])\n",
        "  plot_value_array(i, predictions, np.int_(test_label))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6MKfHjdIWYda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_data, test_label)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "YY2AH6D9WdsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate precision and recall\n",
        "print(\"Precision:\",precision_score(np.int_(test_label),np.argmax(predictions,axis=1)))\n",
        "print(\"Recall:\",recall_score(np.int_(test_label),np.argmax(predictions,axis=1)))"
      ],
      "metadata": {
        "id": "mtwuEk0LYo4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrIwulA_az9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}